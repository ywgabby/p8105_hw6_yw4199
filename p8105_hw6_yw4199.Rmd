---
title: "p8105_hw6_yw4199"
author: "Yaduo Wang"
date: "2023-11-29"
output: github_document
---
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
```

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 2
```{r}
# download the data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

## Problem 3
```{r}
#Load and clean the data for regression analysis.
birthweight <- read.csv("DATA/birthweight.csv")
birthweight = 
  birthweight |> 
#convert numeric to factor
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )
#check for missing data
colSums(is.na(birthweight))
```

After we loading the data, and convert some numeric variables to factor variables as necessary, we check whether there exist missing values. As shown in the results, there is no missing values in each variable. 

```{r}
#Propose a regression model for birth weight with all variables as predictor. 
fit_all = lm(bwt ~., data = birthweight)
summary(fit_all)
```

Select predictors that is significant with small p-value from the summary of the model shown above.

```{r}
# Fit more accurate model. 
fit_selected = lm(bwt ~ babysex + bhead + 
                    blength + delwt + gaweeks +
                    smoken, 
                  data = birthweight)
summary(fit_selected)
```

```{r}
# plot of model residuals against fitted values
birthweight |> 
  modelr::add_residuals(fit_selected) |> 
  modelr::add_predictions(fit_selected) |> 
  ggplot(aes(x = pred, y=resid)) + 
  geom_point(alpha = 0.5) + 
  geom_hline(yintercept = 0) +
  labs(x = "Fitted values", y = "Residuals", 
       title = "Model Residuals vs. Fitted Values")
```

```{r}
# cross validation between two models 
cv_df =crossv_mc(birthweight, 100)
cv_df = 
  cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df |> 
  mutate(
    mine_model = map(train, \(df) lm(bwt ~ babysex + bhead + 
                  blength + delwt + gaweeks + smoken, data = df)),
# One using length at birth and gestational age as predictors (main effects only)
    main_effect_mod  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
# One using head circumference, length, sex, and all interactions (including the three-way interaction) between these.
    interaction_mod     = map(train, \(df) lm(bwt ~ bhead + blength + babysex + 
                                        bhead*blength +
                                        bhead*babysex +
                                        blength*babysex +
                                        bhead * blength * babysex, data = df))
   ) |> 
  mutate(
    rmse_mine = map2_dbl(mine_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main = map2_dbl(main_effect_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_mod, test, \(mod, df) rmse(model = mod, data = df)))
```

```{r}
# compare the distribution of RMSE in plots
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + theme_bw() + 
  labs(x = "Model", y = "RMSE", 
       title = "Models vs. RMSE")
  
```

From the plot, we can see that our original model has the lowest RMSE, so we think that our model might be better compared to other two models in our senarios. 

